{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e100aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# FTP URL\n",
    "url = \"http://ftp.ebi.ac.uk/pub/databases/opentargets/platform/25.03/output/association_overall_direct/\"\n",
    "save_dir = \"openTargets\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# Parse HTML for .parquet links\n",
    "with urllib.request.urlopen(url) as response:\n",
    "    soup = BeautifulSoup(response.read(), \"html.parser\")\n",
    "\n",
    "# Download each .parquet file\n",
    "for link in soup.find_all(\"a\"):\n",
    "    href = link.get(\"href\")\n",
    "    if href.endswith(\".parquet\"):\n",
    "        full_url = url + href\n",
    "        save_path = os.path.join(save_dir, href)\n",
    "        print(f\"Downloading {href}...\")\n",
    "        urllib.request.urlretrieve(full_url, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b98204",
   "metadata": {},
   "source": [
    "### GRAPH THING => \n",
    "### Create a graph of nodes = genes \n",
    "### edges = the euclidean distance of the gene's disease vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9493ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Set the path to your openTargets folder\n",
    "folder_path = \"./openTargets\"\n",
    "\n",
    "# List all files in the folder\n",
    "parquet_files = [f for f in os.listdir(folder_path) if f.endswith('.parquet')]\n",
    "\n",
    "# Initialize an empty list to hold individual DataFrames\n",
    "df_list = []\n",
    "\n",
    "# Read each Parquet file and append the resulting DataFrame to the list\n",
    "for parquet_file in parquet_files:\n",
    "    file_path = os.path.join(folder_path, parquet_file)\n",
    "    df = pd.read_parquet(file_path)  # Read the Parquet file\n",
    "    df_list.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into one\n",
    "openTargets_df = pd.concat(df_list, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a93b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(openTargets_df))\n",
    "openTargets_df.head(30)  # Preview the first few rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "641da207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined DataFrame to a CSV file\n",
    "openTargets_df.to_csv(\"openTargets.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d061fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pronto\n",
    "\n",
    "# Load the ontology\n",
    "ontology = pronto.Ontology(\"http://purl.obolibrary.org/obo/doid.obo\")\n",
    "# Example: map DOIDs to names\n",
    "doid_to_name = {term.id: term.name for term in ontology.terms() if term.id.startswith(\"DOID\")}\n",
    "print(doid_to_name[\"DOID:0050890\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2389affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./Ensembl/Homo_sapiens.GRCh38.113.gtf.gz\", sep='\\t', comment='#', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183e434e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming df is already loaded\n",
    "# Define a function to extract the gene_id and gene_name from the attribute column\n",
    "def extract_gene_info(attributes):\n",
    "    # Split by semicolon and strip whitespace\n",
    "    attributes = attributes.split(';')\n",
    "    \n",
    "    # Initialize the gene_id and gene_name as None\n",
    "    gene_id = None\n",
    "    gene_name = None\n",
    "    \n",
    "    # Loop through the key-value pairs and extract gene_id and gene_name\n",
    "    for attribute in attributes:\n",
    "        if 'gene_id' in attribute:\n",
    "            gene_id = attribute.split('\"')[1]  # Extract value between quotes\n",
    "        elif 'gene_name' in attribute:\n",
    "            gene_name = attribute.split('\"')[1]  # Extract value between quotes\n",
    "    \n",
    "    return pd.Series([gene_id, gene_name])\n",
    "\n",
    "# Use tqdm to apply the function with a progress bar\n",
    "tqdm.pandas(desc=\"Extracting gene info\")\n",
    "\n",
    "# Apply the function to the 'attribute' column with tqdm progress bar\n",
    "gene_info_df = df[8].progress_apply(extract_gene_info)\n",
    "\n",
    "# Set column names\n",
    "gene_info_df.columns = ['gene_id', 'gene_name']\n",
    "\n",
    "# Drop duplicates based on the 'gene_id' and 'gene_name' pair\n",
    "gene_info_df = gene_info_df.drop_duplicates()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0622519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the new DataFrame\n",
    "print(gene_info_df.head())\n",
    "print(len(gene_info_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ec6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load MONDO nodes\n",
    "mondo_df = pd.read_csv(\"./mondo/mondo_nodes.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Drop rows without xrefs\n",
    "mondo_df = mondo_df.dropna(subset=[\"xref\"])\n",
    "\n",
    "xref_to_name = {}\n",
    "\n",
    "# Iterate over rows to extract all xrefs and map them to MONDO name\n",
    "for _, row in mondo_df.iterrows():\n",
    "    name = row['name']\n",
    "    xrefs = row['xref'].split('|')\n",
    "    for xref in xrefs:\n",
    "        xref_to_name[xref] = name\n",
    "\n",
    "# OPTIONAL: include MONDO IDs too\n",
    "for _, row in mondo_df.iterrows():\n",
    "    mondo_id = row['id']\n",
    "    name = row['name']\n",
    "    xref_to_name[mondo_id] = name\n",
    "\n",
    "# Now you can use it like this\n",
    "openTargets_df['diseaseCommonName'] = openTargets_df['diseaseId'].str.replace(\"_\", \":\", regex=False).map(xref_to_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbdcb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_id_to_name = dict(zip(gene_info_df['gene_id'], gene_info_df['gene_name']))\n",
    "\n",
    "# Step 2: Vectorized operations (no swifter needed anymore!)\n",
    "openTargets_df['geneCommonName'] = openTargets_df['targetId'].map(gene_id_to_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55836f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(openTargets_df.head(20))\n",
    "print(len(openTargets_df))\n",
    "print(openTargets_df[\"geneCommonName\"].unique())\n",
    "print(openTargets_df[\"geneCommonName\"].unique().shape)\n",
    "print(openTargets_df[\"diseaseCommonName\"].unique())\n",
    "print(openTargets_df[\"diseaseCommonName\"].unique().shape)\n",
    "missing_disease_rows = openTargets_df[openTargets_df['diseaseCommonName'].isna()]\n",
    "print(missing_disease_rows.head())\n",
    "print(\"Number of missing disease names:\", missing_disease_rows.shape[0])\n",
    "print(openTargets_df['diseaseId'].str.startswith(\"EFO_\").sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "506713d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "openTargets_df = openTargets_df.dropna(subset=[\"diseaseCommonName\", \"geneCommonName\"])\n",
    "len(openTargets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccbf3642",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_as_value = openTargets_df.pivot_table(\n",
    "    index='geneCommonName',\n",
    "    columns='diseaseCommonName',\n",
    "    values='score',\n",
    "    aggfunc='first'  # or 'mean'/'max' if multiple scores exist for same (gene, disease)\n",
    ")\n",
    "print(df_score_as_value.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b42919",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_score_as_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bb541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score_as_value.to_csv(\"./df_score_as_value.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e6a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"ðŸ”¹ Loading dataframe...\")\n",
    "df = pd.read_csv(\"./df_score_as_value.tsv\", sep=\"\\t\", index_col=0)\n",
    "\n",
    "print(\"ðŸ”¹ Extracting genes and score matrix...\")\n",
    "genes = df.iloc[:, 0].to_numpy()\n",
    "score_matrix = df.iloc[:, 1:].fillna(0).to_numpy()\n",
    "\n",
    "print(f\"âœ… Extracted {len(genes)} genes and score matrix of shape {score_matrix.shape}\")\n",
    "\n",
    "print(\"ðŸ”¹ Computing pairwise Cosine distances...\")\n",
    "distances = pdist(score_matrix, metric='cosine')\n",
    "distance_matrix = squareform(distances)\n",
    "\n",
    "print(\"âœ… Distance matrix computed.\")\n",
    "np.save(\"distance_matrix.npy\", distance_matrix)\n",
    "\n",
    "print(\"ðŸ”¹ Building graph with nodes...\")\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(genes)\n",
    "print(\"âœ… Nodes added to graph.\")\n",
    "\n",
    "print(\"ðŸ”¹ Preparing edge list...\")\n",
    "i_upper, j_upper = np.triu_indices(len(genes), k=1)\n",
    "\n",
    "edges = []\n",
    "for i, j in tqdm(zip(i_upper, j_upper), total=len(i_upper), desc=\"Adding edges\"):\n",
    "    edges.append((genes[i], genes[j], {'weight': distance_matrix[i, j]}))\n",
    "\n",
    "print(f\"âœ… Prepared {len(edges)} edges.\")\n",
    "\n",
    "print(\"ðŸ”¹ Adding edges to the graph...\")\n",
    "G.add_edges_from(edges)\n",
    "print(\"âœ… Graph construction complete.\")\n",
    "\n",
    "print(f\"ðŸ“Š Final graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83b2b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"ðŸ”¹ Loading dataframe...\")\n",
    "df = pd.read_csv(\"./df_score_as_value.tsv\", sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95d73cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"bipolar disorder\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78f6b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ðŸ”¹ Extracting genes and score matrix...\")\n",
    "genes = df.index.to_numpy()\n",
    "print(genes)\n",
    "score_matrix = df.iloc[:, 1:].fillna(0).to_numpy()\n",
    "print(score_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befa3910",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"ðŸ”¹ Computing pairwise Cosine distances...\")\n",
    "# distances = pdist(score_matrix, metric='cosine')\n",
    "# sim_matrix = squareform(distances)\n",
    "sim_matrix = np.load(\"distance_matrix.npy\")\n",
    "print(\"ðŸ”¹ Building graph with nodes...\")\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(genes)\n",
    "print(\"âœ… Nodes added to graph.\")\n",
    "print(list(G.nodes)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c6b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep top-K per row\n",
    "K = 50  # Adjust as needed\n",
    "edges = []\n",
    "print(\"ðŸ”¹ Selecting top-K similar genes per gene...\")\n",
    "for i in tqdm(range(sim_matrix.shape[0])):\n",
    "    top_k_idx = np.argpartition(sim_matrix[i], -K)[-K:]\n",
    "    for j in top_k_idx:\n",
    "        if i != j:\n",
    "            weight = sim_matrix[i, j]\n",
    "            edges.append((genes[i], genes[j], {'weight': weight}))\n",
    "print(len(edges))\n",
    "# Build the graph\n",
    "print(\"ðŸ”¹ Constructing graph...\")\n",
    "G = nx.Graph()\n",
    "G.add_nodes_from(genes)\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "print(\"âœ… Graph construction complete.\")\n",
    "print(f\"ðŸ“Š Final graph has {G.number_of_nodes()} nodes and {G.number_of_edges()} edges.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0322f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.write_weighted_edgelist(G, \"50_gene_distance_graph.edgelist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a972c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(G)\n",
    "print(\"Sample nodes:\", list(G.nodes)[:10])\n",
    "print(\"Number of NaN nodes:\", sum(1 for n in G.nodes if str(n) == 'nan' or (isinstance(n, float) and math.isnan(n))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bee70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import community as community_louvain  # python-louvain\n",
    "import networkx as nx\n",
    "G = nx.read_edgelist(\"./50_gene_distance_graph.edgelist\", data=((\"weight\", float),))\n",
    "# Run Louvain community detection\n",
    "partition = community_louvain.best_partition(G, weight='weight', resolution=2.0)  # returns: {gene: community_id}\n",
    "\n",
    "\n",
    "#  Calculate centrality for nodes\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Group nodes by community\n",
    "communities = {}\n",
    "for node, comm_id in partition.items():\n",
    "    if comm_id not in communities:\n",
    "        communities[comm_id] = []\n",
    "    communities[comm_id].append(node)\n",
    "\n",
    "# For each community, sort by degree centrality (you can use other centrality measures)\n",
    "for comm_id, nodes in communities.items():\n",
    "    central_nodes = sorted(nodes, key=lambda x: degree_centrality[x], reverse=True)\n",
    "    print(f\"Community {comm_id} top nodes: {central_nodes[:5]}\")  # Top 5 nodes\n",
    "# # Invert the partition to get community â†’ list of genes\n",
    "# from collections import defaultdict\n",
    "\n",
    "# communities = defaultdict(list)\n",
    "# for gene, community_id in partition.items():\n",
    "#     communities[community_id].append(gene)\n",
    "\n",
    "# # Sort by community ID and print\n",
    "# sorted_communities = dict(sorted(communities.items()))\n",
    "\n",
    "# for cid, members in sorted_communities.items():\n",
    "#     print(f\"Community {cid}: {members}\")\n",
    "    \n",
    "# with open(\"communities_resolution2.0.txt\", \"w\") as f:\n",
    "#     for cid, members in sorted_communities.items():\n",
    "#         f.write(f\"Community {cid}: {', '.join(members)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda1ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate betweenness centrality considering edge weights\n",
    "betweenness_centrality = nx.betweenness_centrality(G, weight='weight')\n",
    "\n",
    "# Group nodes by community\n",
    "for comm_id, nodes in communities.items():\n",
    "    central_nodes = sorted(nodes, key=lambda x: betweenness_centrality[x], reverse=True)\n",
    "    print(f\"Community {comm_id} top nodes by betweenness: {central_nodes[:5]}\")  # Top 5 nodes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ff6940",
   "metadata": {},
   "source": [
    "## Other goal = given a disease, normalize their scores aka have their score = score / total genes then see how our genes compare"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
