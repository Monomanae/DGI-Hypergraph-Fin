{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json\n",
    "from scipy.sparse import load_npz,save_npz,diags,csr_matrix\n",
    "import scipy.sparse as sp\n",
    "import pandas as pd\n",
    "import os\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from pypdf import PdfReader, PdfWriter\n",
    "from tempfile import NamedTemporaryFile\n",
    "import networkx as nx\n",
    "import pickle\n",
    "import gseapy as gp\n",
    "import mygene\n",
    "from IPython.display import display, HTML\n",
    "import re\n",
    "from collections import deque\n",
    "from goatools.obo_parser import GODag\n",
    "import math\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from gseapy.parser import read_gmt\n",
    "import random\n",
    "import igraph as ig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIST_OF_DISEASES = [\"BIPOLAR\",\"SCHIZOPHRENIA\",\"LEUKEMIA\",\"NONE\"]\n",
    "LIST_OF_DISEASES_CLEAN = [x for x in LIST_OF_DISEASES if x != \"NONE\"]\n",
    "SIZE_CAP = 30 # community size cap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(a, b):\n",
    "    a, b = set(a), set(b)\n",
    "    inter = len(a & b)\n",
    "    union = len(a | b)\n",
    "    return inter / union if union else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_to_df = {}\n",
    "for disease in LIST_OF_DISEASES:\n",
    "   disease_to_df[disease] = pd.read_csv(f\"../output/{disease}/important_terms_{disease}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_info(disease):\n",
    "    DISEASE_FOLDER = f\"../output/{disease}/\"\n",
    "    RESULT_FOLDER = DISEASE_FOLDER + \"leiden_results/\"\n",
    "    DGIDB_DIRECTORY = f\"../../Gen_Hypergraph/output/DGIDB_{disease}/\"\n",
    "    RESULT_COMMUNITIES = \"result_communities_new\"\n",
    "    RESULT_GRAPH = \"result_graph_new\"\n",
    "\n",
    "    with open(DISEASE_FOLDER + \"gene_to_index_distinct.json\", \"r\") as file:\n",
    "        gene_to_index_distinct = json.load(file)\n",
    "    with open(DGIDB_DIRECTORY + f\"gene_to_index_{disease}.json\", \"r\") as file:\n",
    "        DGIDB_gene_to_index = json.load(file)\n",
    "    with open(DGIDB_DIRECTORY + f\"drug_to_index_{disease}.json\", \"r\") as file:\n",
    "        DGIDB_drug_to_index = json.load(file)\n",
    "    # Loading result graph and communities\n",
    "    with open(f\"{RESULT_FOLDER}/{RESULT_COMMUNITIES}.pkl\", \"rb\") as f:\n",
    "        communities = pickle.load(f)\n",
    "    # with open(f\"{RESULT_FOLDER}/result_communities_selected.pkl\", \"rb\") as f:\n",
    "    #     communities_selected = pickle.load(f)\n",
    "    with open(f\"{RESULT_FOLDER}/{RESULT_GRAPH}.pkl\", \"rb\") as f:\n",
    "        graph = pickle.load(f)\n",
    "    \n",
    "    DGIDB_genes = set(DGIDB_gene_to_index.keys())\n",
    "    DGIDB_drugs = set(DGIDB_drug_to_index.keys())\n",
    "    index_to_gene_distinct = {v: k for k, v in gene_to_index_distinct.items()}\n",
    "    \n",
    "    return {\"communities\": communities,\n",
    "            # \"communities_selected\": communities_selected,\n",
    "            \"graph\": graph,\n",
    "            \"gene_to_index_distinct\": gene_to_index_distinct,\n",
    "            \"index_to_gene_distinct\": index_to_gene_distinct,\n",
    "            \"DGIDB_gene_to_index\": DGIDB_gene_to_index,\n",
    "            \"DGIDB_drug_to_index\": DGIDB_drug_to_index,\n",
    "            \"DGIDB_genes\": DGIDB_genes,\n",
    "            \"DGIDB_drugs\": DGIDB_drugs\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_info = {}\n",
    "for disease in LIST_OF_DISEASES:\n",
    "    all_info[disease] = load_info(disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all DGIDB genes from other diseases to NONE\n",
    "for disease in LIST_OF_DISEASES_CLEAN:\n",
    "    all_info['NONE']['DGIDB_genes'] = all_info['NONE']['DGIDB_genes'] | all_info[disease]['DGIDB_genes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_info['BIPOLAR']['DGIDB_gene_to_index']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_info['NONE']['DGIDB_genes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter communities by size_cap\n",
    "for disease in LIST_OF_DISEASES:\n",
    "    result_list = []\n",
    "    for community in all_info[disease]['communities']:\n",
    "        if (len(community) >= SIZE_CAP):\n",
    "            result_list.append(community)\n",
    "    all_info[disease]['communities'] = result_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "# Create communities_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Community preprocessing\n",
    "def nx_to_igraph(G: nx.Graph, weight: str | None = \"weight\") -> ig.Graph:\n",
    "    \"\"\"\n",
    "    Convert a NetworkX graph to an iGraph graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph or nx.DiGraph\n",
    "        Your NetworkX graph.\n",
    "    weight : str or None, optional\n",
    "        Name of the edge attribute to treat as weight.\n",
    "        If None, graph is treated as unweighted.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    ig.Graph\n",
    "        An iGraph object with:\n",
    "        - g.vs['name'] = node labels\n",
    "        - g.es['weight'] = weights (if provided)\n",
    "    \"\"\"\n",
    "    # 1) Keep original node labels\n",
    "    nodes = list(G.nodes())\n",
    "    idx_map = {node: i for i, node in enumerate(nodes)}\n",
    "\n",
    "    # 2) Convert edges\n",
    "    edges = [(idx_map[u], idx_map[v]) for u, v in G.edges()]\n",
    "\n",
    "    # 3) Initialize iGraph\n",
    "    g_ig = ig.Graph(edges=edges, directed=G.is_directed())\n",
    "    g_ig.vs[\"name\"] = nodes\n",
    "\n",
    "    # 4) Add weights if available\n",
    "    if weight is not None:\n",
    "        # Extract weights or default to 1.0\n",
    "        weights = [G[u][v].get(weight, 1.0) for u, v in G.edges()]\n",
    "        g_ig.es[\"weight\"] = weights\n",
    "\n",
    "    return g_ig\n",
    "\n",
    "def communities_cutoff(communities, cutoff = 100):\n",
    "    result = []\n",
    "    for community in communities:\n",
    "        if len(community) >= cutoff:\n",
    "            result.append(community)\n",
    "\n",
    "    return result, len(result)\n",
    "\n",
    "def zscore(values):\n",
    "    arr = np.asarray(values, dtype=float)\n",
    "    if arr.size == 0:\n",
    "        return arr\n",
    "\n",
    "    mean = arr.mean()\n",
    "    std = arr.std(ddof=0)\n",
    "\n",
    "    if std == 0 or np.isnan(std):\n",
    "        # no variation: all z-scores = 0\n",
    "        return np.zeros_like(arr)\n",
    "\n",
    "    return (arr - mean) / std\n",
    "\n",
    "def intramodule_closeness(G, community, weight=\"weight\"):\n",
    "    \"\"\"\n",
    "    Intramodule closeness centrality using the induced subgraph of a community.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    G : nx.Graph\n",
    "        Original graph.\n",
    "    community : iterable\n",
    "        Nodes in the community (subset of G).\n",
    "    weight : str or None\n",
    "        Edge attribute to use as weights.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Mapping node -> intramodule closeness centrality.\n",
    "    \"\"\"\n",
    "    # Induced subgraph\n",
    "    H = G.subgraph(community).copy()\n",
    "    H = nx_to_igraph(H, weight=\"weight\")\n",
    "    print(f\"diameter: {H.diameter()}\")\n",
    "    # Regular closeness, but only inside H\n",
    "    cl = H.closeness(weights=\"weight\", normalized=True)\n",
    "    closeness = {H.vs[i][\"name\"]: float(cl[i]) for i in range(H.vcount())}\n",
    "    return closeness\n",
    "\n",
    "def community_central_genes(G, community_nodes, weight=\"weight\", score_cap = 0.1):\n",
    "    closeness_scores = intramodule_closeness(G, community_nodes)\n",
    "    return [u for u in community_nodes if closeness_scores[u] >= score_cap]\n",
    "\n",
    "def pagerank_for_community(g, community_nodes, weight=\"weight\"):\n",
    "    \"\"\"\n",
    "    Compute PageRank for a given community inside an iGraph graph.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    g : igraph.Graph\n",
    "        The iGraph graph (converted from NetworkX).\n",
    "    community_nodes : list\n",
    "        A list of node names (the same labels used in g.vs[\"name\"]).\n",
    "    weight : str or None\n",
    "        Name of the weight attribute. Use None for unweighted Pagerank.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    dict {node_name: pagerank_score}\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Build subgraph by vertex names\n",
    "    sub = g.subgraph(community_nodes)\n",
    "\n",
    "    # 2. Compute PageRank\n",
    "    pr = sub.pagerank(weights=weight)\n",
    "\n",
    "    # 3. Map back: {original_node_name : score}\n",
    "    return {sub.vs[i][\"name\"]: pr[i] for i in range(sub.vcount())}\n",
    "\n",
    "def community_central_genes_by_num(G, community_nodes, weight=\"weight\", top_n=20):\n",
    "    C = set(community_nodes)\n",
    "    H = G.subgraph(C).copy()                       # induced subgraph\n",
    "    # within-community (weighted) degree\n",
    "    k = {u: H.degree(u, weight=weight) for u in H}\n",
    "    ks = np.array(list(k.values()), dtype=float)\n",
    "    zscore_list = zscore(ks)\n",
    "    Z = dict(zip(H,zscore_list))        # within-module degree z-score\n",
    "\n",
    "    # rank by z\n",
    "    ranked = sorted(H.nodes(), key=lambda u: (Z[u]), reverse=True)\n",
    "    return [u for u in ranked[:top_n]]\n",
    "\n",
    "def community_central_genes_by_score(G, community_nodes, weight=\"weight\",score_cap = 1):\n",
    "    C = set(community_nodes)\n",
    "    H = G.subgraph(C).copy()                       # induced subgraph\n",
    "    # within-community (weighted) degree\n",
    "    k = {u: H.degree(u, weight=weight) for u in H}\n",
    "    ks = np.array(list(k.values()), dtype=float)\n",
    "    zscore_list = zscore(ks)\n",
    "    Z = dict(zip(H,zscore_list))        # within-module degree z-score\n",
    "\n",
    "    # rank by z\n",
    "    ranked = sorted(H.nodes(), key=lambda u: (Z[u]), reverse=True)\n",
    "    return [u for u in ranked if Z[u] >= score_cap]\n",
    "\n",
    "def community_central_genes_by_pct(G, community_nodes, weight=\"weight\",pct = 0.3):\n",
    "    C = set(community_nodes)\n",
    "    H = G.subgraph(C).copy()                       # induced subgraph\n",
    "    # within-community (weighted) degree\n",
    "    k = {u: H.degree(u, weight=weight) for u in H}\n",
    "    ks = np.array(list(k.values()), dtype=float)\n",
    "    zscore_list = zscore(ks)\n",
    "    Z = dict(zip(H,zscore_list))        # within-module degree z-score\n",
    "\n",
    "    # rank by z\n",
    "    ranked = sorted(H.nodes(), key=lambda u: (Z[u]), reverse=True)\n",
    "    top = int(len(ranked)*pct)\n",
    "    return [u for u in ranked[:top]]\n",
    "\n",
    "def betweenness_for_community(\n",
    "    g: ig.Graph,\n",
    "    community_nodes,\n",
    "    weight: str | None = \"weight\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute betweenness centrality for nodes inside a community.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    g : ig.Graph\n",
    "        Full igraph graph (must have vs['name']).\n",
    "    community_nodes : list of str\n",
    "        Node names belonging to this community.\n",
    "    weight : str or None\n",
    "        Edge weight attribute name. None = unweighted betweenness.\n",
    "    normalized : bool\n",
    "        Normalize betweenness by maximum possible value.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict {node_name : betweenness_score}\n",
    "    \"\"\"\n",
    "\n",
    "    # Build subgraph of the community\n",
    "    sub = g.subgraph(community_nodes)\n",
    "\n",
    "    # Compute betweenness (igraph does this fast, C-optimized)\n",
    "    bt = sub.betweenness(weights=weight)\n",
    "    bt_normalized = ig.rescale(bt, clamp=True)\n",
    "\n",
    "    # Return mapping {node_name : score}\n",
    "    return {sub.vs[i][\"name\"]: bt_normalized[i] for i in range(sub.vcount())}\n",
    "\n",
    "\n",
    "def zscores_dict(G, community_nodes, weight=\"weight\"):\n",
    "    C = set(community_nodes)\n",
    "    H = G.subgraph(C).copy()                       # induced subgraph\n",
    "    # within-community (weighted) degree\n",
    "    k = {u: H.degree(u, weight=weight) for u in H}\n",
    "    ks = np.array(list(k.values()), dtype=float)\n",
    "    zscore_list = zscore(ks)\n",
    "    Z = dict(zip(H,zscore_list))        # within-module degree z-score\n",
    "\n",
    "    return Z\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "## Betweenness Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "### Load Betweenness Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../output/disease_to_all_betweenness_scores.json\", \"r\") as f:\n",
    "    disease_to_all_betweenness_scores = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_to_all_betweenness_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "### Compute Betweenness Scores (very time consuming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BETWEENNESS_SCORE_CAP = 0.1\n",
    "\n",
    "# disease_to_all_betweenness_scores = {}\n",
    "# for disease in LIST_OF_DISEASES:\n",
    "#     all_betweenness_scores = []\n",
    "#     ds_igraph = nx_to_igraph(all_info[disease]['graph'])\n",
    "#     for community in all_info[disease]['communities']:\n",
    "#         betweenness_scores = betweenness_for_community(ds_igraph,community)\n",
    "#         print(len(community),len([u for u in community if betweenness_scores[u] >= BETWEENNESS_SCORE_CAP]))\n",
    "#         all_betweenness_scores.append(betweenness_scores)\n",
    "#     disease_to_all_betweenness_scores[disease] = all_betweenness_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### Convert Indices to Integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covnert indices to integers\n",
    "for disease, list_of_dicts in disease_to_all_betweenness_scores.items():\n",
    "    for i, subdict in enumerate(list_of_dicts):\n",
    "        disease_to_all_betweenness_scores[disease][i] = {int(k): v for k, v in subdict.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "#### Save the Resulting Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the resulting dictionary\n",
    "# with open(\"../output/disease_to_all_betweenness_scores.json\", \"w\") as f:\n",
    "#     json.dump(disease_to_all_betweenness_scores, f, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "## Compute Degree Z-score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_to_all_zscores = {}\n",
    "for disease in LIST_OF_DISEASES:\n",
    "    all_zscores = []\n",
    "    for community in all_info[disease]['communities']:\n",
    "        zscores = zscores_dict(all_info[disease]['graph'],community)\n",
    "        all_zscores.append(zscores)\n",
    "    disease_to_all_zscores[disease] = all_zscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCORE_CAP = 0\n",
    "\n",
    "for disease in LIST_OF_DISEASES:\n",
    "    all_zscores = disease_to_all_zscores[disease]\n",
    "    communities_selected = []\n",
    "    comms = all_info[disease]['communities']\n",
    "    i = 0\n",
    "    for i in range(len(comms)):\n",
    "        selected_nodes = [u for u in comms[i] if all_zscores[i][u] >= SCORE_CAP]\n",
    "        communities_selected.append(selected_nodes)\n",
    "    all_info[disease]['communities_selected'] = communities_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "# Disease-specific Genes Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "### Genes Similarity Graph Between Diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_common_genes(d1,d2):\n",
    "    return len(all_info[d1]['DGIDB_genes'] & all_info[d2]['DGIDB_genes'])\n",
    "def num_common_drugs(d1,d2):\n",
    "    return len(all_info[d1]['DGIDB_drugs'] & all_info[d2]['DGIDB_drugs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "# add nodes with size attribute\n",
    "for disease in LIST_OF_DISEASES_CLEAN:\n",
    "    G.add_node(disease, size=len(all_info[disease]['DGIDB_genes']))\n",
    "\n",
    "# add weighted edges for all pairs\n",
    "for i in range(len(LIST_OF_DISEASES_CLEAN)):\n",
    "    for j in range(i + 1, len(LIST_OF_DISEASES_CLEAN)):\n",
    "        w = num_common_genes(LIST_OF_DISEASES_CLEAN[i], LIST_OF_DISEASES_CLEAN[j])\n",
    "        G.add_edge(LIST_OF_DISEASES_CLEAN[i], LIST_OF_DISEASES_CLEAN[j], weight=w)\n",
    "\n",
    "# -----------------------------\n",
    "# Draw the graph\n",
    "# -----------------------------\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "\n",
    "node_sizes = [G.nodes[n]['size'] for n in G.nodes]\n",
    "edge_weights = [G[u][v]['weight'] for u, v in G.edges]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "w = edge_weights\n",
    "w_min, w_max = min(w), max(w)\n",
    "edge_widths = [(x - w_min) / (w_max - w_min + 1e-9) * 3 + 0.5 for x in w]\n",
    "\n",
    "nx.draw(\n",
    "    G,\n",
    "    pos,\n",
    "    with_labels=True,\n",
    "    node_size=node_sizes,\n",
    "    width=edge_widths,          # edge width proportional to similarity\n",
    "    edge_color='gray',\n",
    "    font_size=10\n",
    ")\n",
    "\n",
    "label_pos = {n: (x, y + 0.07) for n, (x, y) in pos.items()}\n",
    "nx.draw_networkx_labels(G, label_pos, labels={n: G.nodes[n]['size'] for n in G.nodes})\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels=nx.get_edge_attributes(G, 'weight'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31",
   "metadata": {},
   "source": [
    "### Community Detection Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_community_bipartite(comms1, comms2, jaccard_threshold=0.0, cap=0, graph_label = \"\"):\n",
    "    \"\"\"\n",
    "    Draw a bipartite graph comparing two community detection results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    comms1 : list of iterables\n",
    "        Communities from run 1 (each element is an iterable of node IDs).\n",
    "    comms2 : list of iterables\n",
    "        Communities from run 2.\n",
    "    jaccard_threshold : float, optional\n",
    "        Only draw edges with Jaccard >= threshold.\n",
    "    cap : int, optional\n",
    "        Only include communities with size >= cap.\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # --- filter communities by cap ---\n",
    "    filtered1 = [(i, c) for i, c in enumerate(comms1) if len(c) >= cap]\n",
    "    filtered2 = [(j, c) for j, c in enumerate(comms2) if len(c) >= cap]\n",
    "\n",
    "    # node names\n",
    "    left_nodes  = [f\"A_{i}\" for i, _ in filtered1]\n",
    "    right_nodes = [f\"B_{j}\" for j, _ in filtered2]\n",
    "\n",
    "    # add nodes with size attribute\n",
    "    for i, c in filtered1:\n",
    "        G.add_node(f\"A_{i}\", bipartite=0, comm_idx=i, size=len(c))\n",
    "\n",
    "    for j, c in filtered2:\n",
    "        G.add_node(f\"B_{j}\", bipartite=1, comm_idx=j, size=len(c))\n",
    "\n",
    "    # add edges with jaccard weight\n",
    "    for i, c1 in filtered1:\n",
    "        for j, c2 in filtered2:\n",
    "            jacc = jaccard(c1, c2)\n",
    "            if jacc >= jaccard_threshold:\n",
    "                G.add_edge(f\"A_{i}\", f\"B_{j}\", weight=jacc)\n",
    "\n",
    "    # if no edges and no nodes, nothing to draw\n",
    "    if G.number_of_nodes() == 0:\n",
    "        print(\"No communities passed the cap filter; nothing to draw.\")\n",
    "        return\n",
    "\n",
    "    # --- positions: two vertical columns ---\n",
    "    pos = {}\n",
    "    for k, n in enumerate(left_nodes):\n",
    "        if n in G:\n",
    "            pos[n] = (0, k)\n",
    "    for k, n in enumerate(right_nodes):\n",
    "        if n in G:\n",
    "            pos[n] = (1, k)\n",
    "\n",
    "    # --- node sizes (scale by community size) ---\n",
    "    sizes = [G.nodes[n][\"size\"] for n in G.nodes]\n",
    "    s_min, s_max = min(sizes), max(sizes)\n",
    "    node_sizes = [100 + 900 * (s - s_min) / (s_max - s_min + 1e-9) for s in sizes]\n",
    "\n",
    "    # --- normalized edge widths from Jaccard weights ---\n",
    "    weights = [d[\"weight\"] for _, _, d in G.edges(data=True)]\n",
    "    if weights:\n",
    "        w_min, w_max = min(weights), max(weights)\n",
    "        if w_max > w_min:\n",
    "            edge_widths = [\n",
    "                0.5 + 4 * (w - w_min) / (w_max - w_min)  # thickness in [0.5, 4.5]\n",
    "                for w in weights\n",
    "            ]\n",
    "        else:\n",
    "            edge_widths = [2.0] * len(weights)\n",
    "    else:\n",
    "        edge_widths = []\n",
    "\n",
    "    # labels: A0, A1, ... for comms1; B0, B1, ... for comms2\n",
    "    labels = {\n",
    "        n: f\"{'A' if G.nodes[n]['bipartite']==0 else 'B'}{G.nodes[n]['comm_idx']}\"\n",
    "        for n in G.nodes\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos,\n",
    "        with_labels=False,\n",
    "        node_size=node_sizes,\n",
    "        width=edge_widths,\n",
    "        edge_color=\"gray\",\n",
    "    )\n",
    "    nx.draw_networkx_labels(G, pos, labels=labels, font_size=9)\n",
    "\n",
    "    # edge labels = Jaccard scores\n",
    "    edge_labels = {(u, v): f\"{d['weight']:.2f}\" for u, v, d in G.edges(data=True)}\n",
    "\n",
    "    ax = plt.gca()\n",
    "    offset = 0.04  # tweak this to move labels further/closer\n",
    "\n",
    "    for (u, v), label in edge_labels.items():\n",
    "        x1, y1 = pos[u]\n",
    "        x2, y2 = pos[v]\n",
    "\n",
    "        # midpoint of the edge\n",
    "        mx, my = (x1 + x2) / 2.0, (y1 + y2) / 2.0\n",
    "\n",
    "        # perpendicular unit vector to the edge\n",
    "        dx, dy = x2 - x1, y2 - y1\n",
    "        length = (dx**2 + dy**2) ** 0.5 or 1.0\n",
    "        px, py = -dy / length, dx / length  # rotate (dx,dy) by -90°\n",
    "\n",
    "        # offset midpoint along perpendicular\n",
    "        lx, ly = mx + offset * px, my + offset * py\n",
    "\n",
    "        ax.text(lx, ly, label,\n",
    "                fontsize = 10,\n",
    "                ha=\"center\", va=\"center\")\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(graph_label)\n",
    "    plt.tight_layout()  \n",
    "    plt.show()\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_to_ncbi(comms,index_to_ncbi):\n",
    "    comms_ncbi = [list(map(index_to_ncbi.get, c)) for c in comms]\n",
    "    return comms_ncbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease in LIST_OF_DISEASES:\n",
    "    disease_info = all_info[disease]\n",
    "    all_info[disease]['communities_ncbi'] = index_to_ncbi(disease_info['communities'],\n",
    "                                                          disease_info['index_to_gene_distinct'])\n",
    "    all_info[disease]['communities_selected_ncbi'] = index_to_ncbi(disease_info['communities_selected'],\n",
    "                                                        disease_info['index_to_gene_distinct'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_helper(left,right,jaccard_threshold, cap, code = \"ncbi\"):\n",
    "    com_code = f'communities_{code}'\n",
    "    return draw_community_bipartite(all_info[left][com_code], all_info[right][com_code], jaccard_threshold=jaccard_threshold, cap = cap, graph_label = f\"{left} v.s. {right}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_common_genes(\"LEUKEMIA\",\"SCHIZOPHRENIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease in LIST_OF_DISEASES_CLEAN:\n",
    "    print(f\"{disease}: \")\n",
    "    for c in all_info[disease]['communities_selected']:\n",
    "        print(len(c))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_to_msigdb_comparison = {}\n",
    "for disease in LIST_OF_DISEASES_CLEAN:\n",
    "    disease_to_msigdb_comparison[disease] = draw_helper(disease,\"NONE\",jaccard_threshold=0.1, cap = 0, code = \"selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_helper(\"LEUKEMIA\",\"SCHIZOPHRENIA\",jaccard_threshold=0.1, cap = 100, code = \"selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_helper(\"LEUKEMIA\",\"BIPOLAR\",jaccard_threshold=0.2, cap = 100, code = \"selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_helper(\"BIPOLAR\",\"SCHIZOPHRENIA\",jaccard_threshold=0.05, cap = 100, code = \"selected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "### DGIDB Genes Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DGIDB_count(c,DGIDB_genes_ncbi):\n",
    "    return set(c) & set(DGIDB_genes_ncbi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_comms_DGIDB_num(disease):\n",
    "    i = 0\n",
    "    for c in all_info[disease]['communities_ncbi']:\n",
    "        print(f\"Community {i}: {len(c)}/{len(DGIDB_count(c,all_info[disease]['DGIDB_genes']))}\")\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_comms_DGIDB_num(\"LEUKEMIA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46",
   "metadata": {},
   "outputs": [],
   "source": [
    "BETWEENNESS_SCORE_CAP = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47",
   "metadata": {},
   "outputs": [],
   "source": [
    "for disease in LIST_OF_DISEASES:\n",
    "    DGIDB_genes = all_info[disease]['DGIDB_genes']\n",
    "    comms = all_info[disease]['communities']\n",
    "    comms_ncbi = all_info[disease]['communities_ncbi']\n",
    "    betweenness_scores = disease_to_all_betweenness_scores[disease]\n",
    "    gtid = all_info[disease]['gene_to_index_distinct']\n",
    "    \n",
    "    print(f\"\\033[1m{disease}: \\033[0m\")\n",
    "    for i,(c,s) in enumerate(zip(comms_ncbi,betweenness_scores)):\n",
    "        print(f\"Community {i}:\")\n",
    "        avg_score = sum([val for _,val in s.items()]) / len(s)\n",
    "        print(f\"Average score: {avg_score}\")\n",
    "        dgidb_genes = list(DGIDB_count(c,DGIDB_genes))\n",
    "        dgidb_scores = {g:s[gtid[g]] for g in dgidb_genes}\n",
    "        dgidb_scores_sorted = dict(sorted(dgidb_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        print(dgidb_scores_sorted)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48",
   "metadata": {},
   "outputs": [],
   "source": [
    "DGIDB_count(all_info['LEUKEMIA']['communities_ncbi'][1],all_info['LEUKEMIA']['DGIDB_genes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49",
   "metadata": {},
   "outputs": [],
   "source": [
    "[u for u,v in disease_to_all_betweenness_scores['LEUKEMIA'][1].items() if v >= BETWEENNESS_SCORE_CAP]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {},
   "source": [
    "### Community Detection Similarity (Term-wise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comm_jaccard_bipartite_bestboth(\n",
    "    df1,\n",
    "    df2,\n",
    "    community_col=\"community_id\",\n",
    "    term_col=\"term\",\n",
    "    min_jaccard=0.0,\n",
    "):\n",
    "    # --- 1. Build sets of terms per community ---\n",
    "    comm1 = (\n",
    "        df1[[community_col, term_col]]\n",
    "        .drop_duplicates()\n",
    "        .groupby(community_col)[term_col]\n",
    "        .agg(set)\n",
    "    )\n",
    "    comm2 = (\n",
    "        df2[[community_col, term_col]]\n",
    "        .drop_duplicates()\n",
    "        .groupby(community_col)[term_col]\n",
    "        .agg(set)\n",
    "    )\n",
    "    # --- 2. Best match df1 -> df2 ---\n",
    "    best_12 = {}\n",
    "    for cid1, set1 in comm1.items():\n",
    "        best_score = 0.0\n",
    "        best_cid2 = None\n",
    "        for cid2, set2 in comm2.items():\n",
    "            score = jaccard(set1, set2)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_cid2 = cid2\n",
    "        if best_cid2 is not None and best_score >= min_jaccard:\n",
    "            best_12[(cid1, best_cid2)] = best_score\n",
    "\n",
    "    # --- 3. Best match df2 -> df1 ---\n",
    "    best_21 = {}\n",
    "    for cid2, set2 in comm2.items():\n",
    "        best_score = 0.0\n",
    "        best_cid1 = None\n",
    "        for cid1, set1 in comm1.items():\n",
    "            score = jaccard(set1, set2)\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_cid1 = cid1\n",
    "        if best_cid1 is not None and best_score >= min_jaccard:\n",
    "            best_21[(best_cid1, cid2)] = best_score\n",
    "\n",
    "    # Union of edges from both directions\n",
    "    all_edges = {}\n",
    "    for (c1, c2), s in {**best_12, **best_21}.items():\n",
    "        all_edges[(c1, c2)] = s  # Jaccard is symmetric anyway\n",
    "\n",
    "    # --- 4. Build graph ---\n",
    "    G = nx.Graph()\n",
    "\n",
    "    # Extract community sizes from df1 and df2\n",
    "    size1 = (\n",
    "        df1[[community_col, \"Community Size\"]]\n",
    "        .drop_duplicates()\n",
    "        .set_index(community_col)[\"Community Size\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    size2 = (\n",
    "        df2[[community_col, \"Community Size\"]]\n",
    "        .drop_duplicates()\n",
    "        .set_index(community_col)[\"Community Size\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    # Add nodes for df1 (left)\n",
    "    for cid, terms in comm1.items():\n",
    "        G.add_node(f\"A_{cid}\", side=\"A\", comm_id=cid, size=size1[cid])\n",
    "\n",
    "    # Add nodes for df2 (right)\n",
    "    for cid, terms in comm2.items():\n",
    "        G.add_node(f\"B_{cid}\", side=\"B\", comm_id=cid, size=size2[cid])\n",
    "\n",
    "    # Add edges from union of best matches (both ways)\n",
    "    for (cid1, cid2), score in all_edges.items():\n",
    "        G.add_edge(f\"A_{cid1}\", f\"B_{cid2}\", weight=score)\n",
    "\n",
    "    # --- 5. Layout: two columns ---\n",
    "    left_nodes  = sorted(\n",
    "        [n for n, d in G.nodes(data=True) if d[\"side\"] == \"A\"],\n",
    "        key=lambda n: G.nodes[n][\"comm_id\"],\n",
    "    )\n",
    "    right_nodes = sorted(\n",
    "        [n for n, d in G.nodes(data=True) if d[\"side\"] == \"B\"],\n",
    "        key=lambda n: G.nodes[n][\"comm_id\"],\n",
    "    )\n",
    "\n",
    "    pos = {}\n",
    "    for i, n in enumerate(left_nodes):\n",
    "        pos[n] = (0.0, i)\n",
    "    for i, n in enumerate(right_nodes):\n",
    "        pos[n] = (1.0, i)\n",
    "\n",
    "    # Node size ∝ community size\n",
    "    def size_to_marker(s):\n",
    "        return 3 * s\n",
    "\n",
    "    node_sizes = {n: size_to_marker(G.nodes[n][\"size\"]) for n in G.nodes()}\n",
    "\n",
    "    # Edge width ∝ Jaccard\n",
    "    edge_weights = {(u, v): d[\"weight\"] for u, v, d in G.edges(data=True)}\n",
    "    edge_widths  = [2 + 8 * w for w in edge_weights.values()]\n",
    "\n",
    "    # Edge labels = Jaccard\n",
    "    edge_labels = {(u, v): f\"{w:.2f}\" for (u, v), w in edge_weights.items()}\n",
    "\n",
    "    # Node labels = community IDs\n",
    "    labels = {n: G.nodes[n][\"comm_id\"] for n in G.nodes()}\n",
    "\n",
    "    # --- 6. Plot ---\n",
    "    plt.figure(figsize=(10, max(4, 0.5 * max(len(left_nodes), len(right_nodes)))))\n",
    "\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        nodelist=left_nodes,\n",
    "        node_size=[node_sizes[n] for n in left_nodes],\n",
    "        node_color=\"skyblue\",\n",
    "    )\n",
    "    nx.draw_networkx_nodes(\n",
    "        G, pos,\n",
    "        nodelist=right_nodes,\n",
    "        node_size=[node_sizes[n] for n in right_nodes],\n",
    "        node_color=\"salmon\",\n",
    "    )\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.5)\n",
    "    # nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=7)\n",
    "    \n",
    "    for i, (u, v) in enumerate(G.edges()):\n",
    "        x1, y1 = pos[u]\n",
    "        x2, y2 = pos[v]\n",
    "\n",
    "        # Midpoint of the edge\n",
    "        xm = (x1 + x2) / 2.0\n",
    "        ym = (y1 + y2) / 2.0\n",
    "\n",
    "        # Perpendicular unit vector to the edge\n",
    "        dx = x2 - x1\n",
    "        dy = y2 - y1\n",
    "        length = math.hypot(dx, dy) or 1.0\n",
    "        px = -dy / length\n",
    "        py = dx / length\n",
    "\n",
    "        # Spread labels along the perpendicular direction\n",
    "        # pattern: -2, -1, 0, 1, 2, -2, -1, ...\n",
    "        k = (i % 5) - 2\n",
    "        offset = 0.06 * k   # tune this if you want more/less separation\n",
    "\n",
    "        xl = xm + offset * px\n",
    "        yl = ym + offset * py\n",
    "\n",
    "        w = edge_weights[(u, v)]\n",
    "        label = f\"{w:.2f}\"\n",
    "\n",
    "        plt.text(\n",
    "            xl,\n",
    "            yl,\n",
    "            label,\n",
    "            fontsize=7,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            bbox=dict(boxstyle=\"round,pad=0.1\", fc=\"white\", ec=\"none\", alpha=0.7),\n",
    "        )    \n",
    "    \n",
    "    nx.draw_networkx_labels(G, pos, labels=labels, font_size=8)\n",
    "\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_jaccard_match(\n",
    "    df_source,\n",
    "    df_target,\n",
    "    source_community,\n",
    "    *,\n",
    "    community_col=\"community_id\",\n",
    "    term_col=\"term\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compare one community in df_source to all communities in df_target.\n",
    "    Returns (best_community_in_target, best_jaccard_score, all_scores_series).\n",
    "    \"\"\"\n",
    "\n",
    "    # Terms for the source community\n",
    "    source_terms = set(\n",
    "        df_source.loc[df_source[community_col] == source_community, term_col]\n",
    "    )\n",
    "\n",
    "    if not source_terms:\n",
    "        raise ValueError(f\"No terms found for community {source_community!r} in df_source\")\n",
    "\n",
    "    # Build a mapping: community_id -> set of terms for df_target\n",
    "    target_sets = (\n",
    "        df_target[[community_col, term_col]]\n",
    "        .drop_duplicates()\n",
    "        .groupby(community_col)[term_col]\n",
    "        .agg(set)\n",
    "    )\n",
    "\n",
    "    # Compute Jaccard score against every target community\n",
    "    scores = target_sets.apply(lambda term_set: jaccard(source_terms, term_set))\n",
    "\n",
    "    # Identify the best match\n",
    "    best_community = scores.idxmax()\n",
    "    best_score = scores.loc[best_community]\n",
    "\n",
    "    return best_community, best_score, scores.sort_values(ascending=False)\n",
    "\n",
    "def best_jaccard_analysis_left_to_right(left,right):\n",
    "    for id in disease_to_df[left][\"Community Index\"].unique():\n",
    "        best_comm, best_jaccard, all_scores = best_jaccard_match(\n",
    "            df_source=disease_to_df[left],\n",
    "            df_target=disease_to_df[right],\n",
    "            source_community=id,\n",
    "            community_col=\"Community Index\",  # change if your column name is different\n",
    "            term_col=\"Term\",\n",
    "        )\n",
    "        print(f\"Community {id}:\")\n",
    "        print(\"Best match in right:\", best_comm)\n",
    "        print(\"Best Jaccard score:\", best_jaccard)\n",
    "        print(\"All scores (sorted):\")\n",
    "        \n",
    "        left_DGIDB = DGIDB_count(all_info[left]['communities_ncbi'][id],all_info[left]['DGIDB_genes'])\n",
    "        right_DGIDB = DGIDB_count(all_info[right]['communities_ncbi'][best_comm],all_info[right]['DGIDB_genes'])\n",
    "        print(f\"Number of DGIDB terms left: {len(left_DGIDB)}\")\n",
    "        print(f\"Number of DGIDB terms right: {len(right_DGIDB)}\")\n",
    "        print(f\"Number of common DGIDB terms (with best match): {len(left_DGIDB & right_DGIDB)}\")\n",
    "        \n",
    "        print(all_scores.head())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_comm_jaccard_bipartite_bestboth(\n",
    "    disease_to_df[\"LEUKEMIA\"],\n",
    "    disease_to_df[\"NONE\"],\n",
    "    community_col=\"Community Index\",\n",
    "    term_col=\"Term\",\n",
    "    min_jaccard=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_to_df['NONE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_jaccard_analysis_left_to_right(\"BIPOLAR\",\"NONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56",
   "metadata": {},
   "source": [
    "### L10, S11, B11, N12 Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57",
   "metadata": {},
   "outputs": [],
   "source": [
    "L10 = all_info['LEUKEMIA']['communities_selected_ncbi'][10]\n",
    "S11 = all_info['SCHIZOPHRENIA']['communities_selected_ncbi'][11]\n",
    "B11 = all_info['BIPOLAR']['communities_selected_ncbi'][11]\n",
    "N12 = all_info['NONE']['communities_selected_ncbi'][12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jaccard(L10,S11))\n",
    "print(jaccard(L10,B11))\n",
    "print(jaccard(S11,B11))\n",
    "print(jaccard(S11,N12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59",
   "metadata": {},
   "source": [
    "### TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_to_df['BIPOLAR'][\"Community Index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_to_df['SCHIZOPHRENIA'][\"Community Index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_to_df['LEUKEMIA'][\"Community Index\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_to_df['LEUKEMIA']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64",
   "metadata": {},
   "source": [
    "### Preliminary Gene Comparison (to introduce a new disease)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_DISEASE = \"PARKINSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEW_DGIDB_DIRECTORY = DGIDB_DIRECTORY = f\"../../Gen_Hypergraph/output/DGIDB_{NEW_DISEASE}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NEW_DGIDB_DIRECTORY + f\"gene_to_index_{NEW_DISEASE}.json\", \"r\") as file:\n",
    "    new_DGIDB_gene_to_index = json.load(file)\n",
    "with open(NEW_DGIDB_DIRECTORY + f\"drug_to_index_{NEW_DISEASE}.json\", \"r\") as file:\n",
    "    new_DGIDB_drug_to_index = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_genes = set(new_DGIDB_gene_to_index.keys())\n",
    "new_drugs = set(new_DGIDB_drug_to_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_genes & all_info[\"BIPOLAR\"]['DGIDB_genes']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOZA_genes = [     1813,      6714,     64816,      9429,      1543,        12,\n",
    "            3107,       262,      2952,      3356,     25970,       718,\n",
    "            7365,      4363,      3127,      2904,      1562,     54658,\n",
    "               1,         3,        11,      2740,      2675,      2668,\n",
    "            4524,      1557,      4907,      3350,      4781,      3125,\n",
    "              24,       215,       217,      3359,      2944,      1565,\n",
    "             265, 100302144,      2166,      1576,      1812,      3363,\n",
    "       100302251,        26,      1128,     28755,        22,       218,\n",
    "            5294,      3358,     11201,      2194,      3558,      1993,\n",
    "             887,      5565,      3115,      4160,        23,      6505,\n",
    "            3952,      3699,     23216,      5617,      2641,     84062,\n",
    "            3106,     50852,      9135,      7957,      2289,      6532,\n",
    "              10,       216,      6531,      1544,      5020,        13,\n",
    "           10951,      3727,      3760,      1559,     54657,      5563,\n",
    "            4915,      3176,      4835,         2,       214,     59340,\n",
    "            1815,      3269]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLOZA_genes = set([str(i) for i in CLOZA_genes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CLOZA_genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common genes in communities 8 (both diseases) that are also in CLOZA_genes\n",
    "print(len(CLOZA_genes & DGIDB_count(all_info['BIPOLAR']['communities_ncbi'][8],all_info['BIPOLAR']['DGIDB_genes']) & DGIDB_count(all_info['SCHIZOPHRENIA']['communities_ncbi'][8],all_info['SCHIZOPHRENIA']['DGIDB_genes'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75",
   "metadata": {},
   "source": [
    "# Community Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_communities_attributes_df(disease):\n",
    "    comms = all_info[disease]['communities']\n",
    "    msigdb_comp_graph = disease_to_msigdb_comparison[disease]\n",
    "    edge_list = [(u, v, data[\"weight\"]) for u, v, data in msigdb_comp_graph.edges(data=True)]\n",
    "    comms_ncbi = all_info[disease]['communities_ncbi']\n",
    "    DGIDB_genes = all_info[disease]['DGIDB_genes']\n",
    "    betweenness_scores = disease_to_all_betweenness_scores[disease]\n",
    "    gtid = all_info[disease]['gene_to_index_distinct']\n",
    "    \n",
    "    # compute msigdb connection weight for each community\n",
    "    comm_to_total_weights = {}\n",
    "    \n",
    "    for i in range(len(comms)):\n",
    "        comm_to_total_weights[i] = 0\n",
    "    for edge in edge_list:\n",
    "        weight = edge[2]\n",
    "        comm_id = int(edge[0].split(\"_\")[1])\n",
    "        comm_to_total_weights[comm_id] += weight\n",
    "    \n",
    "    # compute number of DGIDB genes\n",
    "\n",
    "    total_num_dgidb_genes = 0\n",
    "    comm_to_num_dgidb_genes = {}\n",
    "    \n",
    "    for i,c in enumerate(comms_ncbi):\n",
    "        num_dgidb_genes = len(DGIDB_count(c,DGIDB_genes))\n",
    "        total_num_dgidb_genes += num_dgidb_genes\n",
    "        comm_to_num_dgidb_genes[i] = num_dgidb_genes\n",
    "    \n",
    "    \n",
    "    # betweenness score for DGIDB genes\n",
    "\n",
    "    comm_to_betweenness_score = {}\n",
    "    comm_to_average_score = {}\n",
    "    \n",
    "    for i,(c,s) in enumerate(zip(comms_ncbi,betweenness_scores)):\n",
    "        avg_score = sum([val for _,val in s.items()]) / len(s)\n",
    "        comm_to_average_score[i] = avg_score\n",
    "        dgidb_genes = list(DGIDB_count(c,DGIDB_genes))\n",
    "        dgidb_scores = {g:s[gtid[g]] for g in dgidb_genes}\n",
    "        dgidb_scores_sorted = dict(sorted(dgidb_scores.items(), key=lambda x: x[1], reverse=True))\n",
    "        comm_to_betweenness_score[i] = dgidb_scores_sorted\n",
    "    \n",
    "    # # print result\n",
    "    # print(f\"Disease: {disease}\")\n",
    "    # print(f\"Number of communities: {len(comms)}\\n\")\n",
    "    # for i,c in enumerate(comms):\n",
    "    #     print(f\"\\033[1mCommunity {i}:\\033[0m\")\n",
    "    #     print(f\"Total connection weight to MsigDB: {comm_to_total_weights[i]}\")\n",
    "    #     print(f\"Number of DGIDB genes: {comm_to_num_dgidb_genes[i]}\")\n",
    "    #     print(f\"Average betweenness score: {comm_to_average_score[i]}\")\n",
    "    #     print(f\"DGIDB genes betweenness score: {comm_to_betweenness_score[i]}\")\n",
    "    #     print(f\"Total number of DGIDB genes (in communities greater than size_cap): {total_num_dgidb_genes}\")\n",
    "    #     print()\n",
    "        \n",
    "    # create dataframe\n",
    "    community_attributes = pd.DataFrame({\n",
    "        \"msigdb_connection_weight\": comm_to_total_weights,\n",
    "        \"num_dgidb_genes\": comm_to_num_dgidb_genes,\n",
    "        \"avg_btn_score\": comm_to_average_score,\n",
    "        \"dgidb_genes_btn_score\": comm_to_betweenness_score,\n",
    "    })\n",
    "    \n",
    "    return community_attributes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = create_communities_attributes_df('SCHIZOPHRENIA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78",
   "metadata": {},
   "outputs": [],
   "source": [
    "p[p['msigdb_connection_weight'] > 0.60]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# components = list(nx.connected_components(G))\n",
    "# for i, comp in enumerate(components):\n",
    "#     print(f\"Component {i} ({len(comp)} nodes):\")\n",
    "#     print(comp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
